{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFG.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/Android998/TensorFlow2.3/blob/master/TFG.ipynb",
      "authorship_tag": "ABX9TyOdLAFa8B4uDvb1F46MdDBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Android998/TensorFlow2.3/blob/master/TFG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Vt5BoZk8b-"
      },
      "source": [
        "## **Paso 1: Importar las librerias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhZ260AcDBb"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YSbqpAelDtV"
      },
      "source": [
        "## **Paso 2:Pre procesado de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z06ryLWDlCoo",
        "outputId": "5616bd91-52bc-4131-a8da-8f905c81443c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "base_dir = \"./drive/My Drive/object_photos\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PXrwXPQum-A"
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 256\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yVvxCvxuu4e",
        "outputId": "353226fd-1592-43a9-ad0a-21b75a1dafe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "print(len(train_generator))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 38681 images belonging to 40 classes.\n",
            "152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTPH2N3_uwi_",
        "outputId": "8197e3d7-dd96-4046-a2ee-60180d1c13e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')\n",
        "print(len(val_generator))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9652 images belonging to 40 classes.\n",
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNtajZB5XJqp"
      },
      "source": [
        "### **Generamos el archivo labels con las etiquetas de los objetos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHYustr0XCZp",
        "outputId": "9147cc37-0a77-42fd-cdb0-7ee58f24fa09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'backpack': 0, 'bed': 1, 'belt': 2, 'blind stick': 3, 'bottle': 4, 'carpet': 5, 'cellular phone': 6, 'chair': 7, 'cup-glass': 8, 'door': 9, 'eyeglasses': 10, 'fan': 11, 'handkerchief': 12, 'headphones': 13, 'keys': 14, 'laptop': 15, 'mouse': 16, 'newspaper': 17, 'notebook': 18, 'pen': 19, 'pencil': 20, 'pillow': 21, 'plate': 22, 'plug': 23, 'printer': 24, 'radiator': 25, 'remote control': 26, 'shoes': 27, 'shorts': 28, 'socks': 29, 't-shirt': 30, 'table': 31, 'television': 32, 'toothbrush': 33, 'towel': 34, 'trash bin': 35, 'wallet': 36, 'wardrobe': 37, 'watch': 38, 'window (shade)': 39}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ei7YAb_XGB1",
        "outputId": "61051e66-f380-4171-890f-954a4f3a4057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backpack\n",
            "bed\n",
            "belt\n",
            "blind stick\n",
            "bottle\n",
            "carpet\n",
            "cellular phone\n",
            "chair\n",
            "cup-glass\n",
            "door\n",
            "eyeglasses\n",
            "fan\n",
            "handkerchief\n",
            "headphones\n",
            "keys\n",
            "laptop\n",
            "mouse\n",
            "newspaper\n",
            "notebook\n",
            "pen\n",
            "pencil\n",
            "pillow\n",
            "plate\n",
            "plug\n",
            "printer\n",
            "radiator\n",
            "remote control\n",
            "shoes\n",
            "shorts\n",
            "socks\n",
            "t-shirt\n",
            "table\n",
            "television\n",
            "toothbrush\n",
            "towel\n",
            "trash bin\n",
            "wallet\n",
            "wardrobe\n",
            "watch\n",
            "window (shade)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kY07UNKXTmd"
      },
      "source": [
        "## **Paso 3: Crear el modelo base ya entrenado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXwprYu_VRst"
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MwvYSdDPMTh"
      },
      "source": [
        "modelo = tf.keras.models.Sequential()\n",
        "modelo.add(tf.keras.layers.InputLayer(input_shape=IMG_SHAPE))\n",
        "modelo.add(tf.keras.layers.ZeroPadding2D())\n",
        "modelo.add(tf.keras.layers.Conv2D(32, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(4, 4)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Conv2D(128, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Conv2D(64, 3, activation='relu', padding=\"same\"))\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Flatten())\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
        "modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "modelo.add(tf.keras.layers.BatchNormalization())\n",
        "modelo.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
        "modelo.add(tf.keras.layers.Dense(units=40, activation=\"softmax\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xty_0omUOTfG",
        "outputId": "ef15e9fc-33ed-4939-c946-8faf1fd7e988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelo.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 226, 226, 32)      896       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 226, 226, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 226, 226, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 226, 226, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 226, 226, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 226, 226, 64)      256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 226, 226, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 226, 226, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 18, 18, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 40)                10280     \n",
            "=================================================================\n",
            "Total params: 581,416\n",
            "Trainable params: 580,328\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8oS6D2mVKTB"
      },
      "source": [
        "modelo.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "               loss='categorical_crossentropy', \n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp3UykJ8VWcO",
        "outputId": "c2f03323-abd3-4977-9d01-a8f19a4cfbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history = modelo.fit(train_generator, \n",
        "           steps_per_epoch=len(train_generator), \n",
        "           epochs=10,\n",
        "           validation_data=val_generator, \n",
        "           validation_steps=len(val_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNz2I6WUSX6"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMQxHcU9UCJX"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"fashion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krdba2IMUDG4"
      },
      "source": [
        "model.save_weights(\"fashion_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW3CQjWgUjTP"
      },
      "source": [
        "files.download(\"fashion_model.json\")\n",
        "files.download(\"fashion_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}